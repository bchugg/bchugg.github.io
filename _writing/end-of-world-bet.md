---
layout: writing
title: "An end of the world bet"
description: Will AI kill everyone before 2030?
date: "2024-12-20" 
status: published
image: /assets/writing_images/eclipse.jpeg
---

On December 19th, 2024, I sent [Greg Colbourn](https://twitter.com/gcolbourn) $1,000 USD. If the world hasn't ended by January 1st, 2030, Greg will send me $2,000 USD. 

The bet is mostly about AI risk, but of course the nature of the contract is such that I'm betting against the world ending for any other reason (or things generally being so catastrophic that international financial transfers are impossible). 

I view existential risk from AI as essentially a non-problem, so from my perspective this is a relatively safe investment with a ~15% annualized return. Greg feels that there is a significant chance that AI kills everyone by 2030; enough risk that he'd rather have $1000 now than $2000 five years from now. 

_Thanks to [Elliot Olds](https://elliotolds.com/) for helping organize the bet._