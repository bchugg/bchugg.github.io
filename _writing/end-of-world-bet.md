---
layout: writing
title: "My end of the world bets"
description: Will AI kill everyone before 2030?
date: "2024-12-20" 
updated: "2025-02-05"
status: published
image: /assets/writing_images/eclipse.jpeg
---

_Update Feb 5th:_ I sent [MichaÃ«l Trazzi](https://michaeltrazzi.com/) $1,000 USD on February 4th 2025. If we're both alive in January 2030 he'll send me $2,500 USD. 

---

On December 19th, 2024, I sent [Greg Colbourn](https://twitter.com/gcolbourn) $1,000 USD. If the world hasn't ended by January 1st, 2030, Greg will send me $2,000 USD. 

The bet is mostly about AI risk, but of course the nature of the contract is such that I'm betting against the world ending for any other reason (or things generally being so catastrophic that international financial transfers are impossible). 

I view existential risk from AI as essentially a non-problem, so from my perspective this is a relatively safe investment with a ~15% annualized return. Greg feels that there is a significant chance that AI kills everyone by 2030; enough risk that he'd rather have $1000 now than $2000 five years from now. 

_Thanks to [Elliot Olds](https://elliotolds.com/) for helping organize the bet._