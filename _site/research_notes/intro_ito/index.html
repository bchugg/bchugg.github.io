<!DOCTYPE html>
<html lang="en-us">

  <head prefix="og: http://ogp.me/ns#; dc: http://purl.org/dc/terms/#">
  
  
  <!-- Canonical link to help search engines -->
  <link rel="canonical" href="http://localhost:4000/research_notes/intro_ito/" />

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PN2H9928PZ"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-PN2H9928PZ');
  </script>

  <!-- Basic meta elements -->
  <meta charset="utf-8" />

  <!-- Enable responsiveness on mobile devices -->
  <meta name="viewport" content="width=device-width,initial-scale=1.0,shrink-to-fit=no" />

  <!-- Mathjax Support -->
  <script type="text/javascript" async
    src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>

  <title>
    
     Itô Integral: Construction and Basic Properties
    
  </title>

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v3.9.1" />
<meta property="og:title" content="Itô Integral: Construction and Basic Properties" />
<meta name="author" content="Ben Chugg" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="General introduction to stochastic calculus and Itô integration" />
<meta property="og:description" content="General introduction to stochastic calculus and Itô integration" />
<link rel="canonical" href="http://localhost:4000/research_notes/intro_ito/" />
<meta property="og:url" content="http://localhost:4000/research_notes/intro_ito/" />
<meta property="og:site_name" content="benny" />
<meta property="og:image" content="http://localhost:4000/assets/writing_images/brownian_motion.gif" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-16T00:00:00-05:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:image" content="http://localhost:4000/assets/writing_images/brownian_motion.gif" />
<meta property="twitter:title" content="Itô Integral: Construction and Basic Properties" />
<meta name="twitter:site" content="@bennychugg" />
<meta name="twitter:creator" content="@Ben Chugg" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Ben Chugg","url":"https://benchugg.com"},"dateModified":"2022-01-16T00:00:00-05:00","datePublished":"2022-01-16T00:00:00-05:00","description":"General introduction to stochastic calculus and Itô integration","headline":"Itô Integral: Construction and Basic Properties","image":"http://localhost:4000/assets/writing_images/brownian_motion.gif","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/research_notes/intro_ito/"},"url":"http://localhost:4000/research_notes/intro_ito/"}</script>
<!-- End Jekyll SEO tag -->


  <!-- Dublin Core metadata for Zotero -->
  <meta property="dc:title" content="Itô Integral: Construction and Basic Properties" />
  <meta property="dc:creator" content="Ben Chugg" />
  <meta property="dc:identifier" content="http://localhost:4000/research_notes/intro_ito/" />
  
  <meta property="dc:date" content="2022-01-16 00:00:00 -0500" />
  
  <meta property="dc:source" content="benny" />

  <!-- Open Graph and Twitter metadata -->
  <meta property="og:title" content="Itô Integral: Construction and Basic Properties" />
  <meta property="og:url" content="http://localhost:4000/research_notes/intro_ito/" />
  
    <meta property="og:image" content="http://localhost:4000/assets/writing_images/brownian_motion.gif" />
    <meta name="twitter:image" content="http://localhost:4000/assets/writing_images/brownian_motion.gif" />
  
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />
  <meta name="twitter:card" content="summary">
  <meta name="twitter:domain" value="benchugg.com" />
  <meta name="twitter:title" value="Itô Integral: Construction and Basic Properties" />
  <meta name="twitter:url" value="http://localhost:4000" />
  
  <!-- Description is dependent on page type  -->
  
    <meta property="og:description" content="General introduction to stochastic calculus and Itô integration">
    <meta name="twitter:description" value="General introduction to stochastic calculus and Itô integration" />
    <meta property="og:type" content="article" />
  
  

  <!-- CSS link -->
  <link rel="stylesheet" href="/assets/css/style.css" />

  <!-- Icons -->
  <link rel="apple-touch-icon" sizes="167x167" href="/assets/favicon.ico" />
  <link rel="apple-touch-icon-precomposed" sizes="180x180" href="/assets/favicon.ico" />
  <link rel="apple-touch-icon-precomposed" sizes="152x152" href="/assets/favicon.ico">
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/assets/favicon.ico">
  <link rel="apple-touch-icon-precomposed" href="/assets/favicon.ico">
  <link rel="shortcut icon" href="/assets/favicon.ico" />
  <link rel=”apple-touch-icon” sizes="114×114" href="/assets/favicon.ico" />
  <link rel=”apple-touch-icon” sizes="72×72" href="/assets/favicon.ico" />
  <link rel=”apple-touch-icon” href="/assets/favicon.ico" />
  <link rel=”icon” href="/assets/favicon.ico", sizes="32x32"/>

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="http://localhost:4000/atom.xml" />

  
</head>


  <body class="theme-base-">

    <!-- This if statement decides which sidebar to use -->
    
    <!--
  Target for toggling the sidebar `.sidebar-checkbox` is for regular styles, `#sidebar-checkbox` for
  behavior.
-->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<aside class="sidebar" id="sidebar">
  <div class="sidebar-item">
    
  </div> 

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="/">Home</a>

    

    
    
      
        
      
    
      
    
      
    
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/papers/">Papers</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="/research_notes/">Research Notes</a>
        
      
    
      
    
      
    
      
        
          <a class="sidebar-nav-item" href="/writing/">Writing</a>
        
      
    

    <a class='sidebar-nav-item' href="http://incrementspodcast.com">Podcast</a>

    <!-- <span class='sidebar-nav-item'>Recommendations</span>
    <ul class="dropdown-menu">
      
        
          
        
      
        
      
        
      
        
      
        
      
        
          
        
      
        
          
        
      
        
      
        
      
        
          
        
      
    </ul> -->

   </nav> 

  <div class="sidebar-links">
    <div class='container'>
      <a href="https://github.com/bchugg" rel='nofollow'><img src="/assets/images/github_white.png"></a>
      <a href="https://www.linkedin.com/in/ben-chugg-3a4616aa/" rel='nofollow'><img src="/assets/images/linkedin_white.png"></a>
      <a href="https://www.goodreads.com/user/show/90945992-ben-chugg" rel='nofollow'><img src="/assets/images/goodreads_white.png"></a>
      <a href="https://twitter.com/BennyChugg" rel='nofollow'><img src="/assets/images/twitter_white.png"></a>
    </div>
  </div>
</aside>

    

    <!--
      Wrap is the content to shift when toggling the sidebar. We wrap the content to avoid any CSS
      collisions with our real content.
    -->
    <div class="wrap">
      <header class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">benny</a>
            
          </h3>
        </div>
      </header>

      <main class="container content" id="main">
        <article class="note">
  <small>
    <a href="/research_notes/">Back to all notes</a>
  </small>
  <hr>
  
  <p class='title'>Itô Integral: Construction and Basic Properties</p> 
  \[\newcommand{\dif}{\;\text{d}}
\newcommand{\ind}{\mathbf{1}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\F}{\mathcal{F}}
\renewcommand{P}{\mathbb{P}}
\newcommand{\B}{\mathcal{B}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\Var}{\mathbb{V}}\]

<ul id="markdown-toc">
  <li><a href="#1-intro" id="markdown-toc-1-intro">1. Intro</a></li>
  <li><a href="#2-construction" id="markdown-toc-2-construction">2. Construction</a></li>
  <li><a href="#3-properties" id="markdown-toc-3-properties">3. Properties</a>    <ul>
      <li><a href="#31-i_t-is-a-martingale" id="markdown-toc-31-i_t-is-a-martingale">3.1 \(I_T\) is a Martingale</a></li>
      <li><a href="#32-the-itô-isometry" id="markdown-toc-32-the-itô-isometry">3.2 The Itô Isometry</a></li>
      <li><a href="#33-quadratic-variation" id="markdown-toc-33-quadratic-variation">3.3 Quadratic Variation</a></li>
    </ul>
  </li>
  <li><a href="#4-examples" id="markdown-toc-4-examples">4. Examples</a></li>
</ul>

<h1 id="1-intro">1. Intro</h1>
<p>Traditional calculus is fine, sure. But sometimes you have some juicy stochastic processes that don’t obey the requirements for the usual differentiation or integration (in particular, they may be nowhere differentiable). This doesn’t stop us from wanting to try doing something similar with them. <a rel="nofollow noopener noreferrer" href="https://en.wikipedia.org/wiki/It%C3%B4_calculus">Itô calculus</a> is one way of extending the methods of deterministic calculus to the stochastic setting. But it isn’t the only one: there is also <a rel="nofollow noopener noreferrer" href="https://en.wikipedia.org/wiki/Stratonovich_integral">Stratonovich calculus</a>. However, Itô calculus is (arguably) more common, and is also better suited to applications in finance, as we’ll see below. I don’t have much of an interest in mathematical finance, but hey, applications are always nice and they provide useful intuition checks. Stratonovich calculus is used more by physicists and I already have enough physics envy that I don’t need to play into it.</p>

<p>The big payoff of Itô integration will be when dealing with stochastic differential equations, i.e., differential equations where at least one variable is a stochastic process. This post contains the construction and basic properties of the Itô integral, so we won’t actually see the big payoffs yet. But we’ll get there eventually. Vegetables before dessert, people.</p>

<p>Our goal is to make sense of the object</p>

\[\begin{equation*}
    I_T(X) \equiv \int_0^T X\dif W = \int_0^T X_t(\omega)\dif W_t(\omega),
\end{equation*}\]

<p>for stochastic processes \(X\) and \(W\). Both \(X\) and \(W\) are functions of time and some underlying probability space \((\Omega, \F, \P)\). They can be viewed as measurable maps on the product space of \(\Omega\) and the given time interval,</p>

\[X:[0,T]\times \Omega \to\R,\]

<p>with the underlying product measure \(\B_T\otimes\F\) where \(\B_T\) is the Borel \(\sigma\)-algebra on \([0,T]\). Such details will mostly be unimportant and, as usual, we’ll mostly forget the dependence on \(\omega\) and write \(X_t\) or \(X(t)\). But recalling the dependence on elements of \(\Omega\) can be helpful for making sense of certain statements. For instance, for fixed \(\omega \in \Omega\) the integral</p>

\[\int_0^T X(t,\omega)\dif t,\]

<p>is a normal (deterministic) Lebesgue integral whose value is a function of \(\omega\). The expectation over \(\Omega\) is thus also well-defined:</p>

\[\E_\omega\bigg[\int_0^T X(t,\omega) \dif t\bigg]=\E\int_0^T X_t \dif t.\]

<p>We’ll mostly use the notation on the right for conciseness, but keeping the left hand side in mind will help when things get a little hairy.</p>

<p>Before diving into the construction of a whole new object, we should ask ourselves if this is necessary at all. Why don’t the usual notions of integration work here? For one, \(W\) is not a measure, so it’s hard to see how to apply Lebesgue integration. Riemann-Stieltjes integration is an obvious candidate, but this doesn’t work if \(W\) isn’t sufficiently well-behaved. In particular, it should be of bounded variation. Recall that the <em>total variation</em> of a function \(f:[0,T]\to\R\) is defined as</p>

\[V(f) = \sup_\Pi \sum_{t_i} |f(t_i) - f(t_{i-1})|,\]

<p>where the supremum is taken over all partitions \(\Pi=\{t_0,\dots,t_n\}\) of \([0,T]\). The paths of Brownian motion have infinite variation a.s. (almost surely). That is, \(\P(\omega:V(f(\omega))&lt;\infty)=0.\) Stronger still, Brownian motion is a.s. nowhere differentiable (which implies infinite variation), making typical statements from regular calculus such as \(\int X\dif W=\int X \frac{dW}{dt} dt\) impossible here, since the derivative of \(W\) doesn’t exist. Intuitively, this all stems from the fact that Brownian motion is fractal-like in its movement over time (illustrated below). It’s wiggling up and down an infinite amount in every finite time period.</p>

<p><img src="/assets/writing_images/brownian_motion.gif" alt="brownian-motion" style="text-align: center;" /></p>
<p class="caption">
    Example of a single realization of Brownian motion over time. Stolen from <a rel="nofollow noopener noreferrer" href="https://users.math.yale.edu/public_html/People/frame/Fractals/RandFrac/Brownian/BrGrphMovie.html">this beautiful website</a> dedicated to fractals at Yale. Here, the x-axis is time, and the y-axis is the value of the random variable. 
</p>

<p>So it looks like we do in fact need a new notion of integration to handle such stochastic processes. Before we get there, we need to introduce two assumptions on \(X\). First, we’ll assume it’s square integrable in expectation, i.e.,</p>

\[\E\int_0^T X_t^2 \dif t &lt;\infty.\]

<p>This assumption is used when constructing the integral in order to apply to the relevant convergence theorems. Second, we assume that \(X\) is adapted to the process \(W\). Let \((\F_t)_{t\in[0,T]}\) denote the <a rel="nofollow noopener noreferrer" href="https://en.wikipedia.org/wiki/Filtration_(probability_theory)">filtration</a> associated with \(W\), where formally</p>

\[\F_t=\sigma(W_\tau|\tau\leq t)=\sigma(W_\tau^{-1}(S)|S\in\B_\tau,\tau\leq t).\]

<p>Intuitively, \(\F_t\) contains all information about \(W\) up until time \(t\), but no more. \(X\) being adapted to \((\F_t)\) means that \(X_t\) can act on knowledge about the value \(W_\tau\) for \(\tau\leq t\), but not on future values of \(W\). In finance applications, this is equivalent to the assumption that there’s no insider trading: \(X_t\) cannot change depending on some future price. Formally, \(X\) being adapted to \((\F_t)\) means that for every \(t\), \(X_t=X(t,\cdot):\Omega\to \R\) is \(\F_i\) measurable (i.e., it can be completely defined from \(\F_i\)). If this all looks weird, don’t panic. The intuition that \(X\) “can’t see into the future” is good enough for most purposes.</p>

<p>Alright, ‘tis time to construct this bad boy.</p>

<h1 id="2-construction">2. Construction</h1>

<p>Like every other integral you’ve ever seen in your life, the Itô integral is constructed by first defining the integral for simple expressions and then taking some complicated limits for general integrands. And even though we saw that the Riemann-Stieltjes integral won’t suffice here, it’s not a bad place to start.</p>

<p>We start out assuming that our integrand is a <em>simple process</em>. That is,  assume that \(X\) changes value only at discrete times \(0=t_0&lt;t_1&lt;\dots&lt;t_n=T&lt;\infty\). Abusing notation somewhat, write \(X=X_i\) at time \(t_i\), etc. We assume only that \(X\) is simple – \(W\) can still be continuous. Following a similar approach to the Riemann-Stieltjes integral, define</p>

\[\begin{equation}
\label{eq:I_simple}
    I_T(X) = \sum_{i=0}^{n-1} X_i(W_{i+1}-W_i). \tag{1}
\end{equation}\]

<p>To see that this isn’t completely hopeless, we’ll note that this equation has a nice interpretation in finance land (which is where many of the applications we’ll discuss lie, so get used to it).  Suppose \(W\) is the market price of some good you’ve bought, or some stock, and that \(X_i\) is the amount of stock you hold between \([t_i,t_{i+1})\). At time \(t_i\), you pay \(X_iW_i\) to buy \(X_i\) units at price \(W_i\). At time \(t_{i+1}\), at the end of the trading day, the price has changed to \(W_{i+1}\), so you sell your shares and receive a profit of \(X_iW_{i+1}\). So your total gain (or loss, if \(W_{i+1}&lt;W_i\)) for the period \([t_i,t_{i+1})\) is \(X_i(W_{i+1}-W_i)\). Then, at \(t_{i+1}\) you buy \(X_{i+1}\) shares and the process repeats for the interval \([t_{i+1},t_{i+2})\). Over the interval \([t_0,t_n)\), your total wealth is then \(I_T\). Note that this interpretation requires that you sell at the end of each trading period. If you only adjust your price from \(X_i\) to \(X_{i+1}\) when the price changes from \(W_i\) to \(W_{i+1}\), then your total wealth at time \(t_n\) would simply be the amount of stock you hold at that time times the price, minus whatever you paid at the beginning. That is, \(X_{n-1}W_n - X_0W_0\).</p>

<p>It’s worth highlighting the importance of choosing the left endpoint of \(X_i\) in Equation \(\eqref{eq:I_simple}\) over the interval \(W_{i+1}-W_i\), instead of say the middle point \((X_{i+1}-X_i)/2\) (as is done in Stratonovich calculus), or the right endpoint. The choice of left endpoint is suitable for finance: we choose how much stock to buy when we see the price at the beginning of the day. Choosing anything after \(X_i\) would imply seeing into the future. Also, unlike in traditional calculus, this choice matters (due to, as we’ll see, the quadratic variation of \(W\))! Different choices yield different results for even fairly basic integrands.</p>

<p>Now we’d like to extend the definition of the integral to general integrands. The proofs are finnicky and not very illuminating unless you’re really keen on practicing your dominated and bounded convergence theorems. So suffice it to say that the usual tactic works out: Given a a general process \(X\) we construct a sequence of simple processes \(X_n\) which convergence pointwise to \(X\): \(X_n(t,\omega)\to X(t,\omega)\). Then we show that \((X_n(t,\omega)-X(t,\omega))^2\to 0\) and finally that</p>

\[\lim_{n\to\infty}\E\int_0^T (X_n(t,\omega)-X(t,\omega))^2\dif t\to0.\]

<p>This is convergence in \(L^2\), which implies convergence in probability. (If you’ve forgotten your convergence definitions and theorems see <a rel="nofollow noopener noreferrer" href="http://www2.stat.duke.edu/~sayan/CBB2012/convergence.pdf">here</a> for a nice, concise reminder). It’s now natural to define</p>

\[\int_0^T X \dif W \equiv \lim_{n\to\infty}\int_0^T X_n\dif W,\]

<p>(the converence is <a rel="nofollow noopener noreferrer" href="https://en.wikipedia.org/wiki/Convergence_of_random_variables">convergence in probability</a>) where, if you were worried, we’re ensured that the limit exists because \(I_T(X_n)\) is a cauchy sequence. This gives us our Itô integral \(I_T(X)\).</p>

<h1 id="3-properties">3. Properties</h1>

<p>First, just like when we were integrating against \(\dif t\), note that \(I_t=I_t(X)\) is itself a stochastic process:</p>

\[\begin{equation}
\label{eq:ItX}
I_t(X): [0,T]\times \Omega \to \R: (t,\omega)\mapsto \int_0^t X(t,\omega)\dif W(t,\omega). \tag{2}
\end{equation}\]

<p>Right off the bat this lets us know that we’ve really entered distinct territory from regular calculus. To go much further however, we need to start talking a bit about \(W\).</p>

<p>Typically, \(W\) is taken to be a <a rel="nofollow noopener noreferrer" href="https://en.wikipedia.org/wiki/Wiener_process">Wiener Process</a>, i.e., Brownian motion. Recall that (or just believe me if you’ve never seen Brownian motion before) that a one-dimensional Brownian motion \(B\) is a stochastic process satisfying</p>

<ul>
  <li>\(B_0=0\) (we can relax this to any real number but for the Itô integral it’s always taken as 0).</li>
  <li>\(B_{t+\tau} - B_t\), \(\tau\geq 0\) are independent of past values of \(W_s\), \(s\leq t\) (independent increments)</li>
  <li>\(B_{t+\tau}-B_t\sim\mathcal{N}(0,\tau^2)\), \(\tau\geq 0\) (increments are normally distributed)</li>
  <li>\(B_t\) is continuous as a function of \(t\).</li>
</ul>

<p>To get a sense of what this looks like just scroll up and look at the example above again. It looks like that damn stock market trend that you want a try and predict but can’t. Super spikey, super random. If you need more than that right now then, sorry, you’re going to have to Google it, because we have things to do. <a rel="nofollow noopener noreferrer" href="https://studiousguy.com/brownian-motion-examples/">Here</a> are eight examples of brownian motion in real life (albeit most are two dimensional) - don’t have too much fun.</p>

<p>The first thing to note is that \(\E[B_t]=\E[B_t-B_0]=0\), using that \(B_0=0\) and that increments are normally distributed. Also, \(\E[(B_{t+\tau}-B_t)^2] = \Var((B_{t+\tau}-B_t)^2) = \tau^2\) since \(\E[B_{t+\tau}-B_t]^2=0\). We call this final property <em>linear variation</em> of Brownian motion.</p>

<h2 id="31-i_t-is-a-martingale">3.1 \(I_T\) is a Martingale</h2>

<p>If \(W\) is a Wiener process, then it is also a martingale. A continuous time martingale \(Y_t\) with respect to the filtration \(\F_t\) obeys \(\E[\vert Y_t\vert]&lt;\infty\), and, for all \(t\) and \(s\leq t\),</p>

\[\E[Y_t \;\vert \; \F_s] = Y_s.\]

<p>That is, given all information up until time \(s\), the expected value of \(Y\) for all future values is \(Y_s\). If \(\F_s\) is the filtration produced by \(Y\) itself we’ll often just say that \(Y\) is a martingale. The classic example of a martingale is a fair game: if \(Y_t\) is a gambler’s wealth at time \(t\), where the gambler wins $1 if a <em>fair</em> coin lands heads and loses $1 if the coin lands tails, then the sequence \(Y_t\) is a martingale. Given wealth \(Y_s\) at time \(s\), the expected value of future wealth is also \(Y_s\) <em>because the game is fair</em>. An unbiased random walk is another example of a martingale.</p>

<p>Because Brownian motion has independent increments we have</p>

\[\E[W_t \vert \F_s] = \E[W_t - W_s + W_s\vert \F_s] = \E[W_t - W_s \vert \F_s] + W_s = W_s.\]

<p>Also, Jensen’s inequality with \(\varphi:x\mapsto x^2\) gives</p>

\[\E(\vert W_t\vert)^2 \leq \E(\vert W_t\vert^2) = \E[(W_t - W_0)^2] =t^2&lt;\infty,\]

<p>so \(\E(\vert W_t\vert)\) is finite and we see that \(W\) is a martingale.</p>

<p>It turns out that \(I_t\) is also a martingale. This might not come as a suprise though. If we’re trading against an asset \(W\) which is a “fair game”, i.e., it’s as likely to go up as go down, then our wealth over time should not be expected to go up or down either (and there’s no using future information to our advantage because \(X\) is adapted to \(W\)’s filtration).</p>

<p>To see this, suppose again that \(X\) is a simple process with \(X=X_i\) for times \([t_{i},t_{i+1})\). Fix \(t\) and let \(s\leq t\). Let \(0=t_0&lt;t_1&lt;\dots&lt;t_n=t\) be a partition of \([0,t]\). Write</p>

\[\begin{equation}
\label{eq:It_mart}
I_t = \sum_{i=0}^{t_{k-1}} X_i(W_{i+1}-W_i) + X_k(W_{k+1}-W_k) + \sum_{i=k+1}^{n-1} X_i(W_{i+1}-W_i).  \tag{3}
\end{equation}\]

<p>We need to show that \(\E[I_t\vert\F_s]=I_s\). All times in the first sum are prior to \(s\), so are deterministic after conditioning on \(\F_s\) (which, we recall, is all the information up to time \(s\)). For the second term, only \(t_{k+1}&gt;s\), so</p>

\[\E[X_k(W_{k+1}-W_k)\vert \F_s] = X_k(\E[W_{k+1}\vert \F_s] - W_k) = X_k(W_{t_s}-W_k),\]

<p>because \(W\) is a martingale. Thus, the result of the expected value of the first two terms of \(\eqref{eq:It_mart}\) conditioned on \(\F_s\) is precisely \(I_s\). For the final sum, consider some \(i\geq k+1\) and use towered expectations to write</p>

\[\begin{align*}
\E[X_i(W_{i+1}-W_i)\vert\F_s] &amp;= \E[\E(X_i(W_{i+1}-W_i)\vert \F_{t_i})\vert \F_s] \\
&amp;= \E[X_i(\E[W_{i+1}\vert \F_{t_i}] - W_i)\vert \F_s] \\
&amp;= \E[X_i(W_i - W_i)\vert \F_s] =0.
\end{align*}\]

<p>Note that this is only valid since \(\F_s\subset \F_{t_i}\). This implies that the final sum of \(\eqref{eq:It_mart}\) is zero, and we have our result. As you’d expect/hope this carries over into the limit and holds for general integrands of non-simple processes as well.</p>

<h2 id="32-the-itô-isometry">3.2 The Itô Isometry</h2>

<p>Let’s get a little hot and heavy with functional analysis for a second. Given metric spaces \(M_1\) and \(M_2\) with metrics \(d_1\) and \(d_2\), a map</p>

\[f:M_1\to M_2,\]

<p>is an <em>isometry</em> if \(d_1(a,b) = d_2(f(a), f(b))\) for all \(a,b\in M_1\). In other words, the function \(f\) is distance preserving. Now, the Itô integral before specifying an integrand \(X\) can be viewed as a map from the space of all stochastic processes on \([0,T]\times \Omega\) which are (i) square-integrable  (ii) adapted (remember the conditions we outlined above). We denote this space \(L^2_A([0,T]\times \Omega)\). 
Given a process in the space \(X\), \(I_T(X)\) is then a square integrable stochastic process in \(\Omega\) (\(I_T(X)\) is a function of \(\omega\) only). In sum, the Itô integral is a function (or functional, if you prefer)</p>

\[I_T:L^2_A([0,T]\times\Omega)\to L^2(\Omega):X\mapsto I_T(X)\]

<p>(Note the distinction between this equation and Equation \(\eqref{eq:ItX}\), where \(X\) was given and we’re hence already working in \(L^2(\Omega)\).) For two processes \(X,Y\in L^2_A([0,T]\times\Omega)\) consider the metric</p>

\[d_{L^2_A([0,T]\times\Omega)}(X,Y) = \E\int_0^T X_tY_t\dif t.\]

<p>And for \(X,Y\in L^2(\Omega)\) consider the metric</p>

\[d_{L^2(\Omega)}(X,Y)=\E[XY].\]

<p>Equipped with these metrics, the map \(I_T\) is an isometry. That is,</p>

\[d_1(X,Y) = d_2(I_T(X)I_T(Y))=\E[I_T(X)I_T(Y)],\]

<p>or</p>

\[\E\int_0^T X_tY_t\dif t = \E\left(\int_0^T X_t\dif W_t\int_0^T Y_t\dif W_t\right).\]

<p>To prove this, we once again return to simple processes. Given simple \(X\) and \(Y\) which change at times \(\Pi_X=\{t_0^X,t_1^X, \dots,t_n^X\}\) and \(\Pi_Y=\{t_0^Y,t_1^Y,\dots, t_n^Y\}\), consider the partition which is the common refinement of these times, i.e., includes all breakpoints, \(\Pi_X\cup\Pi_Y=\{t_0,t_1,\dots,t_n\}\). Let \(\Delta W_i=W_{i+1}-W_i\). Then,</p>

\[\E\bigg(\int_0^TX_t\dif W_t\int_0^T Y_t\dif W_t\bigg) = \sum_{i,j=0}^{n-1} \E[X_iY_j\Delta W_i\Delta W_j].\]

<p>Fix \(i&lt;j\). Then \(\Delta W_j\) is independent of all of \(X_i\), \(Y_j\), \(\Delta W_i\). It’s indepedent of the first two since \(X_i\) and \(Y_j\) are adapted processes hence determined by \(\F_j\), and of \(\Delta W_i\) because \(W\) of the independent increments property of Brownian motion. Moreover, \(\E[\Delta W_j]=0\) (again by the assumptions of Brownian motion). For \(i=j\) on the other hand, we have \(\E[X_iY_i\Delta W_i^2] = \E[X_iY_i]\E[\Delta W_i^2]=\E[X_iY_i](t_{j+1}-t_j)\) where the second equality uses that \(\Delta W_i\) is independent of \(X_i,Y_i\) because the latter are fully determined by \(\F_i\), and the third uses the linear variaton of brownian motion. This gives</p>

\[\E\bigg(\int_0^TX_t\dif W_t\int_0^T Y_t\dif W_t\bigg) = \sum_i \E[X_iY_i](t_{i+1}-t_i) = \E\int_0^T X_tY_t \dif t,\]

<p>as desired. As a corollary, we can take \(X=Y\) and obtain</p>

\[\E\bigg[\bigg(\int_0^T X_t\dif W_t\bigg)^2\bigg] = \E\int_0^T X_t^2\dif t = \int_0^T \E[X_t^2]\dif t.\]

<p>Notice that we can be a little fast and loose with the order of the expectation the integral from \(0\) to \(T\) because of our assumptions of square-integrability and <a rel="nofollow noopener noreferrer" href="https://en.wikipedia.org/wiki/Fubini%27s_theorem">Fubini’s theorem</a> (in the case of simple processes it’s clear we can switch the order, but Fubini is required for continuous processes.)</p>

<h2 id="33-quadratic-variation">3.3 Quadratic Variation</h2>

<p>The <a rel="nofollow noopener noreferrer" href="https://en.wikipedia.org/wiki/Quadratic_variation">quadratic variation</a> of a stochastic process \(X\) is</p>

\[[X,X](t) = \sup_{\|\Pi\|\to0}\sum_{i=1}^n (X(t_i) - X(t_{i-1}))^2,\]

<p>where \(\Pi\) is a partition of \([0,t]\) and \(\|\Pi\|=\max_j\vert t_{j+1}-t_j\vert\). Clearly, this is similar to the total variation but the term \(X(t_{i}) - X(t_{i-1})\) is squared. Somewhat suprisingly, functions can have infinite total variation but finite quadratic variation – and this is indeed the case with Brownian motion which, over the interval \([a,b]\), has quadratic variation \(b-a\).</p>

<p>Let’s compute the quadratic variation \([I,I](T)\). Once again we suppose that \(X\) is simple and changes values at times \(t_0,t_1,\dots,t_n\). Consider any partition \(\Pi=s_0&lt;s_1&lt;\dots&lt;s_m\) of \([0,T]\). Wlog we can assume that \(\Pi\) is a refinement of \(t_0,t_1,\dots,t_n\) since the mesh goes to zero in the limit anyways. Fix an interval on which \(X\) is constant, \([t_j,t_{j+1})\). Suppose that \(\Pi\) partitions this interval as \(t_j=s_\ell&lt;\dots&lt;s_{\ell+k}=t_{j+1}\). We can of course write \(I_t(X)\) as a function of \(\Pi\). Consider the quadratic variaton on the interval \([t_j,t_{j+1})\):</p>

\[\begin{align*}
\sum_{i=\ell+1}^{\ell+k} (I(s_i)-I(s_{i-1}))^2 &amp;= \sum_{i=\ell+1}^{\ell+k} \bigg(\sum_{z=0}^{i}X_z(W_{z+1}-W_z) - \sum_{z=0}^{i-1}X_z(W_{z+1}-W_z)\bigg)^2 \\
&amp;= \sum_{i=\ell+1}^{\ell+k}(X_i(W_{i+1}-W_i))^2 \\
&amp;= X(t_k)^2\sum_{i=\ell+1}^{\ell+k}(W_{i+1}-W_i)^2.
\end{align*}\]

<p>In the limit, the sum \(\sum_{i=\ell+1}^{\ell+k}(W_{i+1}-W_i)^2\) is precisely quadratic variation of \(W\) on \([t_j,t_{j+1}]\), which is \(t_{j+1}-t_j\). Therefore, on \([t_j,t_{j+1}]\) the quadratic variation of \(I\) is</p>

\[[I,I]([t_j,t_{j+1}]) = X(t_k)^2(t_{j+1}-t_j)=\int_{t_j}^{t_{j+1}} X_t^2 \dif t.\]

<p>Summing across all intervals \([t_0,t_1)\), \([t_1,t_2)\), etc., gives</p>

\[[I,I](T) = \int_0^T X_t^2 \dif t.\]

<p>This might be a little confusing. After all, the quadratic variation of \(W\) on \([0,t]\) is \(t\), a number. But \([I,I](t)\) is a random variable? There’s nothing in the definition of quadratic variation requiring that it converge to a number – this just happens to be a particularly interesting property of Brownian motion.</p>

<h1 id="4-examples">4. Examples</h1>

<p>We can’t get to the end of this thing and not actually calculate the value of any integrals.</p>

<p>Starting with the most basic integral of all: If \(X=c\) is constant, then it’s a simple process on the single interval \([0,T)\) so</p>

\[\int_0^T  c\dif W_t = c(W_{T}-W_0).\]

<p>This is a good sanity check – any other value would be quite suspicious. 
The next example is a classic, and one that highlights a significant difference between Itô calculus and traditional calculus. We will consider \(W\) as the integrand and evaluate</p>

\[\int_0^T W\dif W.\]

<p>Unfortunately, we actually need to do some work to compute this. For each \(n\), define a simple approximation to \(W\) as \(Z_n(t) = W(\frac{jT}{2^n})\) for \(t\in[\frac{jT}{2^n},(j+1)\frac{T}{2^n})\). As you’d expect, \(Z_n\) converges to \(W\):</p>

\[\begin{align*}
\E\int_0^T(Z_n-W)^2\dif t &amp;= \sum_{j=0}^{2^n-1} \int_{jT/2^n}^{(j+1)T/2^n} \E[(Z_n(t)-W(t))^2]\dif t \\ 
&amp;= \sum_{j=0}^{2^n-1} \int_{jT/2^n}^{(j+1)T/2^n} \E[(W(jT/2^n)-W(t))^2]\dif t\\
&amp;= \sum_{j=0}^{2^n} \int_{jT/2^n}^{(j+1)T/2^n} t-\frac{jT}{2^n}\dif t\\
&amp;= \sum_{j=0}^{2^n} \frac{2^{-2n}}{2} = O(2^{-n}) \to 0.
\end{align*}\]

<p>Put \(W_j = W(jT/n)\) and note that</p>

\[\sum_{j=0}^{n-1}W_j(W_{j+1}-W_j) = \frac{1}{2}W_T^2 - \frac{1}{2}\sum_{j=0}^{n-1}(W_{j+1}-W_j)^2.\]

<p>If we take the limit as \(n\to\infty\) of sum on the right hand side, this is precisely the quadratic variation of \(W\), which equals \(T\). Hence,</p>

\[\begin{align}
I_T(W) &amp;= \lim_{n\to\infty}\int_0^T Z_n(t) \dif W_t= \lim_{n\to\infty}\sum_{j=0}^{n-1}W_j(W_{j+1}-W_j)= \frac{W(T)^2}{2} - \frac{T}{2}.
\end{align}\]

<p>This is in marked contrast to ordinary calculus, in which \(\int_0^T x\dif x=T^2/2\), i.e., we do not have the second term of \(T/2\). The culprit is the quadratic variation of the \(W\). The quadratic variation for the usual smooth functions we’re used to integrating ordinarily have quadratic variation 0 (finite total variation implies quadratic variation of zero).</p>

  <small>
    <a href="/research_notes/">Back to all notes</a>
  </small>
</article>
 <!-- "> -->
      </main>

      <!-- Footer  -->
      <div class="container" id="footer">
        <hr>
        <div class='container links'>
          <a href="https://github.com/bchugg" rel='nofollow'><img src="/assets/images/github.png"></a>
          <a href="https://www.linkedin.com/in/ben-chugg-3a4616aa/" rel='nofollow'><img src="/assets/images/linkedin.png"></a>
          <a href="https://www.goodreads.com/user/show/90945992-ben-chugg" rel='nofollow'><img src="/assets/images/goodreads.png"></a>
          <a href="https://twitter.com/BennyChugg" rel='nofollow'><img src="/assets/images/twitter.png"></a>
        </div>
      
        <div class='copyright'>
          <small>&#169; 2022 Ben Chugg</small>
        </div>
      
      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script>

    // Highlight search Query
    var url = window.location.href;
      if (url.lastIndexOf("?q=") > 0) {
        // get the index of the parameter, add three (to account for length)
        var stringloc = url.lastIndexOf("?q=") + 3;
        // get the substring (query) and decode
        var searchquery = decodeURIComponent(url.substr(stringloc));
        // regex matches at beginning of line, end of line or word boundary, useful for poetry
        var regex = new RegExp("(?:^|\\b)(" + searchquery + ")(?:$|\\b)", "gim");
        // get, add mark and then set content
        var content = document.getElementById("main").innerHTML;
        document.getElementById("main").innerHTML = content.replace(regex, "<mark>$1</mark>");
      }

      // Toggle sidebar
      (function(document) {
        var toggle = document.querySelector('.sidebar-toggle');
        var sidebar = document.querySelector('#sidebar');
        var checkbox = document.querySelector('#sidebar-checkbox');

        document.addEventListener('click', function(e) {
          var target = e.target;

          if(!checkbox.checked ||
             !sidebar.contains(target) ||
             (target === checkbox || target === toggle)) return;

          checkbox.checked = false;
        }, false);
      })(document);
    </script>

<!-- Facebook SDK for JavaScript -->
<script>
  window.fbAsyncInit = function() {
    FB.init({
      appId      : '589495744558280',
      xfbml      : true,
      version    : 'v2.6'
    });
  };

  (function(d, s, id){
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) {return;}
     js = d.createElement(s); js.id = id;
     js.src = "//connect.facebook.net/en_US/sdk.js";
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script>
  </body>
</html>
